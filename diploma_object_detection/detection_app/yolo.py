import os
from concurrent.futures.thread import ThreadPoolExecutor

import cv2
import torch
import numpy as np
from pathlib import Path
from tqdm import tqdm
from ultralytics import YOLO
from django.conf import settings
import time
import queue
from multiprocessing import Process, Queue

from threading import Event
import psutil

# –®–ª—è—Ö –¥–æ –º–æ–¥–µ–ª—ñ
MODEL_PATH = os.path.join(settings.BASE_DIR, 'detection_app', 'best.pt')

# –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ –æ–¥–∏–Ω —Ä–∞–∑ –ø—Ä–∏ —ñ–º–ø–æ—Ä—Ç—ñ —Ç–∞ –ø–µ—Ä–µ–º—ñ—â–µ–Ω–Ω—è –Ω–∞ GPU, —è–∫—â–æ –¥–æ—Å—Ç—É–ø–Ω–∏–π
model = YOLO(os.path.join(settings.BASE_DIR, 'detection_app', 'best.pt'))
device = 'cuda' if torch.cuda.is_available() else 'cpu'
model.to(device)

# –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤ –¥–ª—è —à–≤–∏–¥—à–æ—ó —Ä–æ–±–æ—Ç–∏
model.conf = 0.4  # –ø–æ—Ä—ñ–≥ –≤–ø–µ–≤–Ω–µ–Ω–æ—Å—Ç—ñ
model.iou = 0.5  # –ø–æ—Ä—ñ–≥ IoU –¥–ª—è NMS
model.max_det = 100  # –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –≤–∏—è–≤–ª–µ–Ω—å

print(f"YOLO –º–æ–¥–µ–ª—å —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω–∞ –Ω–∞ –ø—Ä–∏—Å—Ç—Ä–æ—ó: {device}")


def detect_image(image_path):
    """–†–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è –æ–±'—î–∫—Ç—ñ–≤ –Ω–∞ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—ñ"""
    try:
        # –ß–∏—Ç–∞—î–º–æ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è
        img = cv2.imread(image_path)
        if img is None:
            raise Exception(f"–ù–µ –≤–¥–∞–ª–æ—Å—è –ø—Ä–æ—á–∏—Ç–∞—Ç–∏ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è: {image_path}")

        # –ó–º—ñ–Ω—é—î–º–æ —Ä–æ–∑–º—ñ—Ä –¥–ª—è —à–≤–∏–¥—à–æ—ó –æ–±—Ä–æ–±–∫–∏, —è–∫—â–æ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –∑–∞–Ω–∞–¥—Ç–æ –≤–µ–ª–∏–∫–µ
        h, w = img.shape[:2]
        if max(h, w) > 1280:
            scale = 1280 / max(h, w)
            img = cv2.resize(img, (int(w * scale), int(h * scale)))

        # 1. –î–µ—Ç–µ–∫—Ü—ñ—è
        results = model(img)[0]  # –±–µ—Ä–µ–º–æ –ø–µ—Ä—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç

        # 2. –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
        result_img = results.plot()

        # 3. –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –æ–±—Ä–æ–±–ª–µ–Ω–æ–≥–æ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è
        result_dir = os.path.join(settings.MEDIA_ROOT, 'results')
        os.makedirs(result_dir, exist_ok=True)

        result_filename = f"result_{Path(image_path).stem}.jpg"
        result_path = os.path.join(result_dir, result_filename)
        cv2.imwrite(result_path, result_img)

        return result_path, results

    except Exception as e:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –¥–µ—Ç–µ–∫—Ü—ñ—ó –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è: {e}")
        return None, None


def detect_video(video_path):
    """–†–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è –æ–±'—î–∫—Ç—ñ–≤ –Ω–∞ –≤—ñ–¥–µ–æ –∑ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è–º –ø–æ—Ç–æ–∫—ñ–≤"""
    try:
        # 1. –í—ñ–¥–∫—Ä–∏–≤–∞—î–º–æ –≤—ñ–¥–µ–æ –¥–ª—è —á–∏—Ç–∞–Ω–Ω—è
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            raise Exception("–ù–µ –≤–¥–∞–ª–æ—Å—è –≤—ñ–¥–∫—Ä–∏—Ç–∏ –≤—ñ–¥–µ–æ—Ñ–∞–π–ª")

        # 2. –û—Ç—Ä–∏–º—É—î–º–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ –≤—ñ–¥–µ–æ
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        fps = int(cap.get(cv2.CAP_PROP_FPS))
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

        # –ü–µ—Ä–µ–≤—ñ—Ä–∏–º–æ —Ä–æ–∑–º—ñ—Ä –≤—ñ–¥–µ–æ —ñ –∑–º–µ–Ω—à–∏–º–æ –π–æ–≥–æ –¥–ª—è —à–≤–∏–¥—à–æ—ó –æ–±—Ä–æ–±–∫–∏, —è–∫—â–æ –ø–æ—Ç—Ä—ñ–±–Ω–æ
        target_size = 640  # —Ü—ñ–ª—å–æ–≤–∞ –≤–∏—Å–æ—Ç–∞ –∞–±–æ —à–∏—Ä–∏–Ω–∞ –¥–ª—è –æ–±—Ä–æ–±–∫–∏
        resize_factor = 1.0
        if width > target_size or height > target_size:
            resize_factor = target_size / max(width, height)
            new_width = int(width * resize_factor)
            new_height = int(height * resize_factor)
            print(f"–ó–º–µ–Ω—à–µ–Ω–Ω—è —Ä–æ–∑–º—ñ—Ä—É –∫–∞–¥—Ä—ñ–≤ –¥–ª—è –æ–±—Ä–æ–±–∫–∏: {width}x{height} -> {new_width}x{new_height}")
        else:
            new_width, new_height = width, height

        # 3. –ì–æ—Ç—É—î–º–æ —Ç–∏–º—á–∞—Å–æ–≤–∏–π –≤–∏—Ö—ñ–¥–Ω–∏–π —Ñ–∞–π–ª
        result_dir = os.path.join(settings.MEDIA_ROOT, 'results')
        os.makedirs(result_dir, exist_ok=True)
        output_filename = f"result_video_{Path(video_path).stem}_{int(time.time())}.mp4"
        output_path = os.path.join(result_dir, output_filename)

        # 4. –ù–∞–ª–∞—à—Ç–æ–≤—É—î–º–æ –≤—ñ–¥–µ–æ–∑–∞–ø–∏—Å
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # –∞–±–æ 'avc1' –¥–ª—è h264
        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))

        # 5. –°—Ç–≤–æ—Ä—é—î–º–æ —á–µ—Ä–≥–∏ —Ç–∞ –ø–æ–¥—ñ—ó –¥–ª—è –º—ñ–∂–ø–æ—Ç–æ–∫–æ–≤–æ—ó –∫–æ–º—É–Ω—ñ–∫–∞—Ü—ñ—ó
        frame_queue = queue.Queue(maxsize=30)  # —á–µ—Ä–≥–∞ –¥–ª—è –∑—á–∏—Ç–∞–Ω–∏—Ö –∫–∞–¥—Ä—ñ–≤
        result_queue = queue.Queue(maxsize=30)  # —á–µ—Ä–≥–∞ –¥–ª—è –æ–±—Ä–æ–±–ª–µ–Ω–∏—Ö –∫–∞–¥—Ä—ñ–≤
        stop_event = Event()  # –ø–æ–¥—ñ—è –¥–ª—è –∑—É–ø–∏–Ω–∫–∏ –ø–æ—Ç–æ–∫—ñ–≤

        # –†–∞—Ö—É—î–º–æ –∫–∞–¥—Ä–∏
        processed_frames = 0
        all_detections = []

        # 6. –§—É–Ω–∫—Ü—ñ—è –¥–ª—è –∑—á–∏—Ç—É–≤–∞–Ω–Ω—è –∫–∞–¥—Ä—ñ–≤ —É –æ–∫—Ä–µ–º–æ–º—É –ø–æ—Ç–æ—Ü—ñ
        def read_frames():
            nonlocal processed_frames
            frame_count = 0

            try:
                while cap.isOpened() and not stop_event.is_set():
                    ret, frame = cap.read()
                    if not ret:
                        break

                    frame_count += 1

                    # –ü—Ä–æ–ø—É—Å–∫–∞—î–º–æ –∫–∞–¥—Ä–∏ –¥–ª—è –ø—Ä–∏—Å–∫–æ—Ä–µ–Ω–Ω—è (–æ–±—Ä–æ–±–ª—è—î–º–æ –∫–æ–∂–µ–Ω N-–π –∫–∞–¥—Ä)
                    skip_factor = 3  # –Ω–∞–ª–∞—à—Ç—É–π—Ç–µ –∑–∞–ª–µ–∂–Ω–æ –≤—ñ–¥ –ø–æ—Ç—Ä–µ–±–∏
                    if frame_count % skip_factor != 0:
                        # –î–ª—è –ø—Ä–æ–ø—É—â–µ–Ω–∏—Ö –∫–∞–¥—Ä—ñ–≤ –∑–±–µ—Ä—ñ–≥–∞—î–º–æ –æ—Ä–∏–≥—ñ–Ω–∞–ª
                        result_queue.put((frame, None, frame_count))
                        continue

                    # –ó–º–µ–Ω—à—É—î–º–æ —Ä–æ–∑–º—ñ—Ä –∫–∞–¥—Ä—É –¥–ª—è —à–≤–∏–¥—à–æ—ó –æ–±—Ä–æ–±–∫–∏
                    if resize_factor < 1.0:
                        resized_frame = cv2.resize(frame, (new_width, new_height))
                        frame_queue.put((resized_frame, frame, frame_count))
                    else:
                        frame_queue.put((frame, None, frame_count))

                    processed_frames += 1
            except Exception as e:
                print(f"–ü–æ–º–∏–ª–∫–∞ –≤ –ø–æ—Ç–æ—Ü—ñ –∑—á–∏—Ç—É–≤–∞–Ω–Ω—è –∫–∞–¥—Ä—ñ–≤: {e}")
            finally:
                # –°–∏–≥–Ω–∞–ª—ñ–∑—É—î–º–æ –ø—Ä–æ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—è
                frame_queue.put((None, None, -1))
                print("–ó—á–∏—Ç—É–≤–∞–Ω–Ω—è –∫–∞–¥—Ä—ñ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–æ")

        # 7. –§—É–Ω–∫—Ü—ñ—è –¥–ª—è –æ–±—Ä–æ–±–∫–∏ –∫–∞–¥—Ä—ñ–≤ —É –æ–∫—Ä–µ–º–æ–º—É –ø–æ—Ç–æ—Ü—ñ
        def process_frames():
            try:
                batch_size = 4  # —Ä–æ–∑–º—ñ—Ä –±–∞—Ç—á—É –¥–ª—è –æ–±—Ä–æ–±–∫–∏
                batch_frames = []
                batch_originals = []
                batch_indices = []

                while not stop_event.is_set():
                    # –û—Ç—Ä–∏–º—É—î–º–æ –∫–∞–¥—Ä –∑ —á–µ—Ä–≥–∏
                    frame, original, frame_idx = frame_queue.get()

                    # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –Ω–∞ —Å–∏–≥–Ω–∞–ª –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—è
                    if frame is None:
                        break

                    # –î–æ–¥–∞—î–º–æ –∫–∞–¥—Ä –¥–æ –±–∞—Ç—á—É
                    batch_frames.append(frame)
                    batch_originals.append(original if original is not None else frame)
                    batch_indices.append(frame_idx)

                    # –Ø–∫—â–æ –∑—ñ–±—Ä–∞–ª–∏ –±–∞—Ç—á –∞–±–æ —Ü–µ –æ—Å—Ç–∞–Ω–Ω—ñ–π –∫–∞–¥—Ä
                    if len(batch_frames) >= batch_size or frame_queue.qsize() == 0:
                        # –û–±—Ä–æ–±–ª—è—î–º–æ –±–∞—Ç—á —Ä–∞–∑–æ–º
                        results = model(batch_frames, verbose=False)

                        # –û–±—Ä–æ–±–ª—è—î–º–æ –∫–æ–∂–µ–Ω —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                        for i, (res, orig_frame, frame_idx) in enumerate(zip(results, batch_originals, batch_indices)):
                            # –í—ñ–∑—É–∞–ª—ñ–∑—É—î–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –Ω–∞ –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–æ–º—É –∫–∞–¥—Ä—ñ
                            result_frame = res.plot()

                            # –Ø–∫—â–æ –±—É–≤ —Ä–µ—Å–∞–π–∑, –ø–æ–≤–µ—Ä—Ç–∞—î–º–æ –¥–æ –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–æ–≥–æ —Ä–æ–∑–º—ñ—Ä—É
                            if resize_factor < 1.0:
                                result_frame = cv2.resize(result_frame, (width, height))

                            # –ó–±–∏—Ä–∞—î–º–æ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ –¥–µ—Ç–µ–∫—Ü—ñ—ó
                            frame_detections = []
                            for box in res.boxes:
                                cls_id = int(box.cls.item())
                                conf = float(box.conf.item())
                                label = res.names[cls_id]

                                frame_detections.append({
                                    'label': label,
                                    'confidence': conf,
                                    'frame': frame_idx
                                })

                            # –î–æ–¥–∞—î–º–æ –¥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
                            result_queue.put((result_frame, frame_detections, frame_idx))

                        # –û—á–∏—â–∞—î–º–æ –±–∞—Ç—á
                        batch_frames = []
                        batch_originals = []
                        batch_indices = []
            except Exception as e:
                print(f"–ü–æ–º–∏–ª–∫–∞ –≤ –ø–æ—Ç–æ—Ü—ñ –æ–±—Ä–æ–±–∫–∏ –∫–∞–¥—Ä—ñ–≤: {e}")
            finally:
                # –°–∏–≥–Ω–∞–ª—ñ–∑—É—î–º–æ –ø—Ä–æ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—è
                result_queue.put((None, None, -1))
                print("–û–±—Ä–æ–±–∫–∞ –∫–∞–¥—Ä—ñ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–æ")

        # 8. –§—É–Ω–∫—Ü—ñ—è –¥–ª—è –∑–∞–ø–∏—Å—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
        def write_results():
            nonlocal all_detections

            try:
                results_count = 0
                frames_buffer = {}  # –±—É—Ñ–µ—Ä –¥–ª—è –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –ø–æ—Ä—è–¥–∫—É –∫–∞–¥—Ä—ñ–≤
                next_frame_idx = 1  # –Ω–∞—Å—Ç—É–ø–Ω–∏–π —ñ–Ω–¥–µ–∫—Å –∫–∞–¥—Ä—É –¥–ª—è –∑–∞–ø–∏—Å—É

                progress_bar = tqdm(total=total_frames, desc="–û–±—Ä–æ–±–∫–∞ –≤—ñ–¥–µ–æ")

                while not stop_event.is_set():
                    # –û—Ç—Ä–∏–º—É—î–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                    result_frame, detections, frame_idx = result_queue.get()

                    # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –Ω–∞ —Å–∏–≥–Ω–∞–ª –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—è
                    if result_frame is None and frame_idx == -1:
                        break

                    # –î–æ–¥–∞—î–º–æ –≤ –±—É—Ñ–µ—Ä
                    frames_buffer[frame_idx] = (result_frame, detections)

                    # –ó–∞–ø–∏—Å—É—î–º–æ –∫–∞–¥—Ä–∏ –ø–æ –ø–æ—Ä—è–¥–∫—É
                    while next_frame_idx in frames_buffer:
                        frame, dets = frames_buffer.pop(next_frame_idx)
                        out.write(frame)

                        if dets is not None:
                            all_detections.append(dets)

                        progress_bar.update(1)
                        next_frame_idx += 1
                        results_count += 1

                # –ó–∞–ø–∏—Å—É—î–º–æ –∑–∞–ª–∏—à–æ–∫ –∫–∞–¥—Ä—ñ–≤
                for idx in sorted(frames_buffer.keys()):
                    frame, dets = frames_buffer[idx]
                    out.write(frame)

                    if dets is not None:
                        all_detections.append(dets)

                    progress_bar.update(1)
                    results_count += 1

                progress_bar.close()
                print(f"–ó–∞–ø–∏—Å–∞–Ω–æ {results_count} –∫–∞–¥—Ä—ñ–≤")

            except Exception as e:
                print(f"–ü–æ–º–∏–ª–∫–∞ –≤ –ø–æ—Ç–æ—Ü—ñ –∑–∞–ø–∏—Å—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤: {e}")

        # 9. –ó–∞–ø—É—Å–∫–∞—î–º–æ –ø–æ—Ç–æ–∫–∏ —á–µ—Ä–µ–∑ ThreadPoolExecutor
        with ThreadPoolExecutor(max_workers=3) as executor:
            read_thread = executor.submit(read_frames)
            process_thread = executor.submit(process_frames)
            write_thread = executor.submit(write_results)

            try:
                # –ß–µ–∫–∞—î–º–æ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—è –≤—Å—ñ—Ö –ø–æ—Ç–æ–∫—ñ–≤
                read_thread.result()
                process_thread.result()
                write_thread.result()
            except Exception as e:
                print(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –≤–∏–∫–æ–Ω–∞–Ω–Ω—ñ –ø–æ—Ç–æ–∫—ñ–≤: {e}")
                stop_event.set()  # –∑—É–ø–∏–Ω—è—î–º–æ –≤—Å—ñ –ø–æ—Ç–æ–∫–∏ —É –≤–∏–ø–∞–¥–∫—É –ø–æ–º–∏–ª–∫–∏

        # 10. –ó–∞–∫—Ä–∏–≤–∞—î–º–æ —Ä–µ—Å—É—Ä—Å–∏
        cap.release()
        out.release()

        print(f"–û–±—Ä–æ–±–∫—É –≤—ñ–¥–µ–æ –∑–∞–≤–µ—Ä—à–µ–Ω–æ! –ó–Ω–∞–π–¥–µ–Ω–æ {len(all_detections)} –¥–µ—Ç–µ–∫—Ü—ñ–π")
        return output_path, all_detections

    except Exception as e:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –¥–µ—Ç–µ–∫—Ü—ñ—ó –≤—ñ–¥–µ–æ: {e}")
        import traceback
        traceback.print_exc()
        return None, []


def detect_webcam_frame(frame):
    """–†–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è –æ–±'—î–∫—Ç—ñ–≤ –Ω–∞ –∫–∞–¥—Ä—ñ –∑ –≤–µ–±-–∫–∞–º–µ—Ä–∏"""
    try:
        # –ó–º–µ–Ω—à—É—î–º–æ —Ä–æ–∑–º—ñ—Ä –¥–ª—è —à–≤–∏–¥—à–æ–≥–æ —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è
        h, w = frame.shape[:2]
        if max(h, w) > 640:
            scale = 640 / max(h, w)
            resized_frame = cv2.resize(frame, (int(w * scale), int(h * scale)))
        else:
            resized_frame = frame

        # 1. –î–µ—Ç–µ–∫—Ü—ñ—è
        results = model(resized_frame)[0]

        # 2. –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
        result_frame = results.plot()

        # –ü–æ–≤–µ—Ä—Ç–∞—î–º–æ –¥–æ –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–æ–≥–æ —Ä–æ–∑–º—ñ—Ä—É, —è–∫—â–æ –∑–º—ñ–Ω—é–≤–∞–ª–∏
        if max(h, w) > 640:
            result_frame = cv2.resize(result_frame, (w, h))

        # 3. –ó–±–∏—Ä–∞—î–º–æ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ —Ä–æ–∑–ø—ñ–∑–Ω–∞–Ω—ñ –æ–±'—î–∫—Ç–∏
        detections = []
        for box in results.boxes:
            cls_id = int(box.cls.item())
            conf = float(box.conf.item())
            label = results.names[cls_id]

            # –î–æ–¥–∞—î–º–æ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∏ –±–æ–∫—Å—É
            bbox = box.xyxy[0].tolist()  # –∫–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ –¥–æ —Å–ø–∏—Å–∫—É [x1, y1, x2, y2]

            detections.append({
                'label': label,
                'confidence': conf,
                'bbox': bbox
            })
        print(f"üîç –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è CPU –ø—ñ—Å–ª—è –æ–±—Ä–æ–±–∫–∏ –≤—ñ–¥–µ–æ: {psutil.cpu_percent(interval=1)}%")
        return result_frame, detections

    except Exception as e:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –¥–µ—Ç–µ–∫—Ü—ñ—ó –∫–∞–¥—Ä—É –≤–µ–±-–∫–∞–º–µ—Ä–∏: {e}")
        # –£ –≤–∏–ø–∞–¥–∫—É –ø–æ–º–∏–ª–∫–∏ –ø–æ–≤–µ—Ä—Ç–∞—î–º–æ –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–∏–π –∫–∞–¥—Ä
        return frame, []